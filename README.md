![header](https://capsule-render.vercel.app/api?type=soft&color=auto&height=300&section=header&text=vaccine%20Review💉&fontSize=90)

# 🦠 COVID Vaccine Controversy Analysis by BERT/DeBERTa
**온라인 댓글 기반 코로나 백신 여론 분석 프로젝트**

[![Python](https://img.shields.io/badge/Python-3776AB?style=flat-square&logo=Python&logoColor=white)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=flat-square&logo=PyTorch&logoColor=white)](https://pytorch.org/)
[![Hugging Face](https://img.shields.io/badge/Hugging%20Face-FFD21C?style=flat-square&logo=huggingface&logoColor=black)](https://huggingface.co/)
[![Transformers](https://img.shields.io/badge/Transformers-FF9A00?style=flat-square&logo=amazonapigateway&logoColor=white)](https://github.com/huggingface/transformers)
[![Pandas](https://img.shields.io/badge/Pandas-150458?style=flat-square&logo=pandas&logoColor=white)](https://pandas.pydata.org/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-F7931E?style=flat-square&logo=scikitlearn&logoColor=white)](https://scikit-learn.org/)
[![BERTopic](https://img.shields.io/badge/BERTopic-000000?style=flat-square&logo=python&logoColor=white)](https://github.com/MaartenGr/BERTopic)

---

## 0. 프로젝트 개요

이 프로젝트는 코로나 백신을 둘러싼 온라인 논쟁을 대규모 댓글·리뷰 데이터에 기반해 분석하는 것을 목표로 한다. Reddit, WebMD, HealthBoards, Drugs.com 등 서로 다른 성격의 사이트에서 약 10만 건에 달하는 문장을 수집한 뒤, 여러 단계의 전처리와 필터링을 거쳐 코로나/백신 논의에 실제로 해당하는 텍스트만 남긴 고순도 데이터셋을 구축하였다. 이후 약 2,100~2,200개의 문장을 사람이 직접 라벨링하고, 이를 바탕으로 DeBERTa v3 기반 Binary 감성 분류 모델을 학습하였다. 마지막으로 BERTopic과 HDBSCAN을 이용해 토픽 구조를 추출하고, 감성 라벨과 결합하여 어떤 이슈들이 부정 여론을 특히 강하게 끌어올리는지 분석하였다.

프로젝트의 전체 흐름은 다음 그림과 같이 요약할 수 있다.

![파이프라인 개요](images/pipe.png)

---

## 1. 서론

### 1.1 왜 “백신 논란 댓글”을 주제로 선택했는가

이 프로젝트에서 코로나 백신과 관련된 온라인 댓글을 분석 대상으로 선택한 데에는 필자의 경험과 진로, 그리고 팬데믹 시기에 느꼈던 문제의식이 함께 작용하였다. 첫째, 필자는 경험적으로 예방접종과 백신을 신뢰하는 입장이다. 대한민국은 오래전부터 높은 예방접종률을 유지해 왔으며, 이는 보편적인 공중보건의 일부로 받아들여져 왔다. 그럼에도 코로나 팬데믹 기간 동안 “백신 부작용”과 “백신 불신”은 온라인에서 가장 격렬하게 논쟁된 주제 중 하나였다. 이 상황을 보면서, 과연 백신에 대한 부정적 여론이 실제 부작용의 크기 때문인지, 아니면 다른 요인이 더 크게 작용하는지에 대한 의문이 생겼다.

둘째, 팬데믹 기간 동안 사람들의 감정과 생각은 뉴스 기사 본문보다는 댓글·포럼·SNS에서 훨씬 더 직접적으로 드러나는 양상을 보였다. 뉴스 기사는 주로 정책 발표나 통계 수치와 같은 사실을 전달하는 데 초점을 맞추지만, 온라인 댓글에는 “그래서 나는 불안하다”, “정부가 믿기 어렵다”, “그래도 맞는 것이 맞다”와 같은 감정과 해석이 그대로 드러난다. 필자는 백신 논쟁을 이해하기 위해서는 기사 본문이 아니라, 이러한 댓글 영역을 따로 떼어 분석할 필요가 있다고 판단했다.

셋째, 필자는 제약회사의 공정·시장 분석 분야를 진로로 고려하고 있다. 약품, 특히 백신과 같은 의약품에 대해 소비자와 환자가 온라인에서 어떤 감정을 표현하는지는 실제 산업 현장에서 매우 중요한 정보가 된다. 따라서 약품에 대한 감정과 여론을 데이터로 계량해 보는 작업은 단순한 학교 과제를 넘어, 향후 진로와도 직접 연결되는 의미 있는 연습이라고 생각했다.

넷째, 학창 시절 실제로 코로나19 팬데믹을 겪으면서, 수많은 방역 대책과 정책들이 충분한 데이터에 기반하지 않은 채 추진되거나, 현장과 괴리를 보이는 장면을 여러 번 목격했다. 그 결과는 종종 사회적 비용 낭비나 신뢰 붕괴로 이어졌다. “지피지기면 백전불태”라는 말처럼, 사람들이 실제로 무엇을 두려워하고, 무엇에 분노하며, 무엇을 불공정하게 느끼는지를 데이터로 파악하는 일은 다음 팬데믹에서 우리가 어떤 의사결정과 커뮤니케이션 전략을 선택해야 하는지 미리 설계하는 출발점이 될 수 있다. 이 프로젝트는 그러한 문제의식을 바탕으로 설계된 시도이다.

### 1.2 연구 배경

COVID-19 팬데믹 동안 각국 정부와 보건 기구는 백신 접종을 팬데믹 대응 전략의 핵심 축으로 삼았다. 백신은 중증과 사망을 줄이는 데 기여한 것으로 평가되지만, 동시에 부작용 논란, 접종 의무화, 마스크·방역 정책을 둘러싸고 강한 사회적 갈등과 불신을 낳았다. 팬데믹이 어느 정도 진정된 이후에도 “백신은 과연 안전하고 효과적이었는가?”, “정부와 제약 회사는 정보를 충분히 공개했는가?”라는 질문은 온라인 공간에서 계속 반복되고 있다.

이러한 문제의식은 개인적인 인상에만 근거한 것이 아니다. 보건학과 커뮤니케이션 연구에서는 백신의 의학적 효과 못지않게 백신에 대한 신뢰와 여론이 방역 정책의 성패를 좌우한다는 점이 반복적으로 강조되어 왔다. 특히 Reddit, 의료 정보 사이트, 약품 리뷰 사이트 등에 축적되는 댓글과 후기는 전통적인 설문조사로 포착하기 어려운 자발적인 감정, 불만, 음모론, 피로감을 드러내는 자료로 주목받고 있다.

한편 온라인 댓글 데이터는 매우 많은 양을 확보할 수 있다는 장점이 있지만, 주제와 직접 관련 없는 잡담, 정치·이념 논쟁, 단순 링크 공유, 사실 검증이 어려운 개인 경험담과 소문 등이 뒤섞여 있다는 한계를 동시에 가진다. 따라서 단순히 “긍정/부정 비율”만 계산하는 방식으로는 백신 논쟁의 구조를 제대로 이해하기 어렵다. 이 때문에 대규모 데이터를 수집하는 것과 더불어, 코로나/백신 논의에 실제로 해당하는 텍스트만 선별하고, 감성과 토픽 구조를 체계적으로 분석하는 작업이 필요하다.

### 1.3 연구 목적 및 핵심 질문

본 프로젝트의 목적은 코로나 백신을 둘러싼 온라인 논쟁을 데이터 기반으로 구조화하는 것이다. 이를 위해 세 가지 핵심 질문을 설정하였다. 첫째, Reddit, WebMD, HealthBoards, Drugs.com 등 서로 다른 사이트에서 수집한 코로나/백신 관련 댓글·리뷰를 하나의 코퍼스로 통합했을 때, 이 데이터셋은 전반적으로 어떤 감성 분포(부정 vs 긍정)를 보이는가. 둘째, 약 2천여 개의 수동 라벨링 데이터를 바탕으로 DeBERTa v3 Binary 감성 분류 모델을 학습했을 때, 백신에 대한 긍·부정 정서를 어느 정도 안정적으로 판별할 수 있는가. 셋째, BERTopic과 HDBSCAN을 이용해 토픽 모델링을 적용하면 어떤 이슈들이 부정 여론을 특히 강하게 끌어올리는지, 예를 들어 부작용과 후유증, 접종 의무화와 해고 위협, 의료비와 병원 시스템, 음모론과 정부/제약사 불신과 같은 주제가 각각 어떤 감성과 결합하는지를 파악할 수 있는가를 묻는다.

이러한 질문을 통해 단순히 “긍정이 많은가, 부정이 많은가”를 넘어, 어떤 유형의 이야기가 어떤 방향의 감성을 동반하는지, 다시 말해 백신 논쟁의 토픽–감성 결합 구조를 확인하는 것을 목표로 한다.

### 1.4 연구 범위와 한계

연구 범위는 다음과 같이 정리할 수 있다. 데이터 출처는 Reddit, WebMD, HealthBoards, Drugs.com 등 영어권 온라인 커뮤니티와 의료 정보·약품 리뷰 사이트로 한정하였다. 분석 언어 역시 영어를 중심으로 진행하였고, 한국어 데이터는 KoELECTRA 기반 실험 수준에서 확장 가능성만 탐색하였다. 감성 분류 설정은 최종적으로 부정과 긍정 두 가지로 구성된 Binary 분류에 초점을 맞추었다. 3-Class(부정/중립/긍정) 설정도 실험하였으나, 데이터 규모와 라벨 일관성 측면에서 Binary 분류가 더 안정적인 결과를 보여 주 모델로 채택하였다. 토픽 모델링은 LDA를 사용해 초기 이슈 지형을 탐색한 후, 최종 해석은 BERTopic과 HDBSCAN을 이용한 결과를 중심으로 진행하였다.

동시에 본 연구에는 몇 가지 한계가 존재한다. 온라인 댓글과 리뷰는 자기 선택 편향(self-selection bias)을 내포하고 있어, 강한 감정을 가진 이용자가 더 자주 글을 남길 가능성이 높다. 일부 텍스트는 개인 경험담과 소문, 음모론에 기반하고 있어 의료·역학적 사실과 반드시 일치하지 않는다. 수동 라벨링 데이터(약 2,100~2,200개)는 딥러닝 모델 학습 관점에서 매우 큰 규모는 아니기 때문에, 라벨 노이즈와 해석의 모호성이 완전히 제거되었다고 보기는 어렵다. 그럼에도 이 프로젝트는 대규모 온라인 데이터를 전처리와 주제 필터링, 감성 분석, 토픽 모델링까지 하나의 파이프라인으로 연결했다는 점에서, 코로나 백신 여론 연구에 의미 있는 기초 자료를 제공한다고 판단하였다.

---

## 2. 데이터 수집 및 코퍼스 구성

데이터는 서로 다른 특성을 가진 네 가지 주요 소스에서 수집하였다. Reddit는 익명성이 높고 긴 토론이 활발한 포럼 형태의 사이트로, 코로나와 백신을 둘러싼 정치·사회적 논쟁이 많이 이루어졌다. WebMD는 의료 정보 제공 사이트로, 기사와 건강 정보 페이지에 달린 댓글에서 건강 상태, 의사 상담 경험, 백신 부작용에 대한 서술이 자주 나타난다. HealthBoards는 질병과 치료, 약물을 주제로 한 Q&A 포럼으로, 가족의 건강 상태와 장기 부작용에 대한 우려를 담은 장문의 고민 글이 많다. Drugs.com은 약품 리뷰 사이트로, 백신 종류, 나이, 구체적인 부작용, “다시 맞을 의향이 있는지” 등의 정보를 함께 제공하는 구조화된 후기가 많이 쌓여 있다.

사이트별 데이터의 분포와 규모는 다음 그림과 같이 정리하였다.

![사이트별 데이터 분포](images/site_distribution.png)

크롤링은 각 사이트에 맞는 방식으로 진행하였다. Reddit의 경우 PRAW 라이브러리를 이용해 API 기반으로 데이터를 수집하였다. 먼저 Reddit API 계정을 통해 client_id, client_secret, user_agent를 발급받아 클라이언트를 초기화한 뒤, 코로나와 백신 논쟁이 활발했던 서브레딧을 선정하였다. 이어서 `subreddit.top(time_filter="all", limit=POST_LIMIT)`와 같은 메서드를 사용해 상위 게시글을 가져오고, `submission.comments.replace_more(limit=None)` 호출 이후 `submission.comments.list()`로 대댓글까지 포함한 전체 댓글 트리를 평탄화하여 수집하였다. 이 과정에서 `[deleted]`, `[removed]` 등 삭제된 댓글은 수집 단계에서 1차적으로 제외하였다. 또한 `created_utc` 필드를 사람이 읽기 쉬운 날짜·시각 형식의 `created_at`으로 변환해 CSV 형태로 저장하였다.

WebMD, HealthBoards, Drugs.com의 경우에는 requests와 BeautifulSoup를 이용한 HTML 크롤링 방식을 사용하였다. 각 사이트별로 “covid vaccine”과 같은 검색 쿼리를 정의하고, 검색 결과 페이지에서 각 글과 리뷰 페이지로 이동하여 본문 텍스트와 작성 시각, 가능한 경우 평점과 추가 메타데이터를 추출하였다. 광고 영역, 추천 글 목록, 사이트 공지 등 본문과 직접 관련이 없는 영역은 CSS 셀렉터 단위에서 제거하였다. 페이지네이션을 따라가며 일정 상한까지 수집하되, 동일 URL이 중복 수집되지 않도록 URL 기반 중복 제거를 수행하였다.

크롤링과 전처리 결과는 여러 단계의 CSV 파일로 관리하였다.

| 파일명                        | 역할/내용 |
|------------------------------|-----------|
| `FINAL_DATA_CLEANED_READY.csv`      | 여러 소스에서 크롤링한 원본 데이터를 기본적인 정제(삭제된 글, 너무 짧은 글, 비영어 등)까지 마친 통합본 |
| `FINAL_DATA_FILTERED_TRUE.csv`      | 위 통합본에서 코로나/백신 관련 키워드가 포함된 행만 남긴 버전. True/False 중, 분석에 사용하는 “관련 있음(True)” 데이터 |
| `FINAL_DATA_ROWS_DELETED.csv`       | True 데이터 중에서도 링크만 공유하거나 의견/감정이 거의 없는 문장을 추가로 제거한 버전 |
| `FINAL_DATA_ROWS_DELETED_2.csv`     | 위 삭제 과정에서, 링크를 공유하면서도 감정이 드러나는 문장 일부(423건)를 복구한 버전 |
| `FEAR_INDEX.csv`                    | 외부에서 가져온 공포·탐욕 지수(Fear-Greed Index) 시계열 데이터. 날짜 기준으로 부정 비율 시계열과 합쳐 상관/DTW 분석에 사용 |
| `DDDD.csv`                          | 최종 분석용 메인 데이터셋. 전처리와 주제 필터링, 링크/중립 삭제까지 거친 후, DeBERTa Binary 모델의 감성 라벨이 부여된 상태의 데이터 |
| `labeled_output.csv` 등             | 수동 라벨링 결과와 모델 예측 결과를 비교·검증하기 위한 출력 파일 |

실제 댓글·리뷰의 예시는 다음과 같다. Reddit에서는 “Had chills after the shot, but honestly it's nothing compared to getting covid. My parents are getting theirs next week...”와 같은 문장이 등장하여 백신 접종 후 부작용을 언급하면서도 코로나 감염 위험과 비교하는 상대적 위험 인식을 드러낸다. WebMD에서는 “After the Moderna vaccine I had chills and a fever for one night. I was scared because of all the news, but my doctor said it was a normal immune response...”와 같이 언론 보도로 인한 불안과 의사의 설명 사이에서 경험을 해석하는 댓글이 나타난다. HealthBoards에서는 “My mom is in the hospital and they're talking about this new vaccine. I'm worried about long term side effects, but also about her catching covid while waiting...”처럼 가족의 입원 상황과 백신·코로나 감염 위험을 동시에 두고 고민하는 글이 많다. Drugs.com에서는 “Vaccine: [brand]. Age: 35. Side effects: sore arm, mild headache, fatigue for 2 days. Would still recommend, it's better than the risks of covid.”와 같은 구조화된 후기에서 부작용과 추천 여부가 함께 제시된다.

---

## 3. 데이터 전처리

전처리의 목표는 단순히 텍스트를 “깔끔하게” 만드는 수준을 넘어, 코로나/백신 논쟁과 실제로 관련된 문장만 남긴 고순도 데이터셋을 구축하는 데 있다. 이를 위해 텍스트 정제와 주제 관련성 필터링이라는 두 축을 모두 고려하였다.

우선 구조적 노이즈를 제거하는 단계에서는 `[deleted]`, `[removed]`, `[No Content]` 등 이미 삭제된 게시물과 내용이 전혀 없는 글을 제거하였다. 또한 “lol”, “ok”처럼 20자 미만이면서 5단어 미만인 매우 짧은 문장은 감정과 의견을 충분히 드러내기 어렵다고 보고 노이즈로 간주하였다. 다음으로 언어 필터링을 적용하여 비영어 문자 비율이 일정 기준 이상인 문장을 제거하였다. 영어 기반 사전학습 모델을 사용할 것이므로, 영어 위주의 일관된 코퍼스를 확보하는 것이 중요했다.

형식적 노이즈를 제거하는 단계에서는 URL과 HTML 태그, 과도한 특수문자, 이모티콘 등을 제거하고, 모든 텍스트를 소문자로 통일한 뒤 공백을 정규화하였다. 마지막으로 코로나/백신과 무관한 일반 잡담을 줄이기 위해 주제 관련성 필터링을 적용하였다. 이를 위해 백신, 코로나, 부작용, 제약사, 접종 의무, 마스크, 미접종자, 병원, 사망, long covid, mRNA 등 코로나/백신 논쟁에서 실제로 자주 등장하는 키워드 목록을 정의하고, 문장 안에 이 키워드 중 하나도 포함되지 않으면 “주제 무관(False)”으로 간주하여 제거하였다.

전처리 단계별 데이터 수의 변화는 다음과 같다.

| 단계 | 설명 | 남은 데이터 수(대략) |
|------|------|------------------------|
| 0. Raw merged | 여러 사이트에서 크롤링 후 기본적인 형식 통일만 수행한 상태 | 약 98,278건 |
| 1. 구조적 노이즈 제거 | `[deleted]`, 너무 짧은 잡담, 내용 없는 문장 제거 | 약 90,000건 내외 |
| 2. 언어 필터링 | 비영어 텍스트 제거 | 약 82,000건 |
| 3. 주제 관련성 필터링 | 코로나/백신 관련 키워드가 하나도 없는 문장 제거 | True: 23,939건 / False: 75,338건 |
| 4. 링크·정보 공유 위주 문장 제거 | 기사 링크만 공유하거나 의견/감정이 거의 없는 문장 추가 삭제 | 약 23,352건 |
| 5. 최종 분석·학습용 데이터 | 날짜·텍스트·사이트 정보가 완비된 최종본 | 20,929건 |

이 과정을 거치면서 약 10만 건이던 원시 데이터는 2만여 건의 고순도 데이터셋으로 압축되었다. 중요한 점은 단순히 데이터 양을 줄인 것이 아니라, 백신 논쟁과 감정을 드러내는 문장만 남기도록 설계했다는 점이다. 전처리 단계별 데이터 수 변화를 시각화하면 다음과 같다.

![전처리 단계별 데이터 수](images/preprocess_counts.png)

구현 과정에서는 전처리 강도가 다른 여러 버전을 실험하였다. 특수문자와 이모티콘 제거, 소문자 변환 정도만 적용한 최소 전처리 버전에서는 LDA 토픽 모델링 결과 상위 키워드에 `http`, `www`, `com`, `trump`, `biden`, `news`와 같은 단어가 과도하게 등장하여, 코로나와 백신 자체보다는 뉴스 링크 공유와 정치 담론에 치우친 토픽이 많이 나타났다. 이 결과를 통해 이러한 수준의 전처리만으로는 “백신 논란의 구조”를 보기 어렵다는 결론을 얻었다. 반면 키워드 기반 주제 관련성 필터를 강화한 버전에서는 LDA 상위 단어에서 `mask`, `vaccine`, `company`, `money`, `hospital` 등 실제 이슈 관련 단어가 뚜렷하게 등장하기 시작했고, 최종 파이프라인은 이 강화된 버전을 기반으로 구축되었다.

전처리의 구체적인 효과를 보여 주기 위해 Reddit에서 가져온 실제 댓글 하나가 단계별로 어떻게 변하는지 예시를 제시하면 다음과 같다.

| 단계 | 텍스트 |
|------|--------|
| Raw 원문 | "Here's the link to the article about covid vaccines: https://[...] Honestly I'm scared of the side effects, but also I don't want my dad to end up in the hospital again." |
| 최소 전처리 | "heres the link to the article about covid vaccines https honestly im scared of the side effects but also i dont want my dad to end up in the hospital again" |
| 키워드 필터 통과 여부 | `covid`, `vaccines`, `side effects`, `hospital`이 포함되어 주제 관련(True)으로 유지 |

이 예시에서 최소 전처리는 형식적 노이즈를 제거하는 역할을 하며, 키워드 필터는 이 문장이 실제로 코로나/백신 논의에 해당하는지 판단하는 역할을 한다. 최종적으로는 형식적으로 깨끗하면서도 의미상으로 코로나/백신 논쟁에 속하는 문장만 남도록 설계하였다.

---

## 4. 수동 라벨링 및 감성 분류 모델

감성 분류 모델의 신뢰성을 확보하기 위해 전체 데이터 중 약 10% 수준인 2,100~2,200개의 문장을 무작위로 추출하여 사람이 직접 라벨링하였다. 각 문장에 대해 부정(0)과 긍정(1)으로 구성된 Binary 감성 라벨과, 부정/중립/긍정 세 가지로 구성된 3-Class 감성 라벨을 동시에 부여하였다. 그러나 실제 실험 결과 3-Class 설정에서는 부정과 중립, 중립과 긍정의 경계가 모호한 문장이 많아 라벨 노이즈에 취약했고, 모델 성능도 상대적으로 불안정하였다. 반면 Binary 설정에서는 동일한 데이터에서 더 일관된 성능과 안정성을 보여, 최종적으로 부정 vs 긍정 이진 분류를 중심으로 파이프라인을 구성하였다.

수동 라벨링의 실제 예시를 보면, “The vaccine saved my parents. They both caught covid before and this time it was just like a mild cold.”와 같은 문장은 백신 접종 후 감염이 경미해졌다는 서술이므로 긍정(1)으로 라벨링하였다. “I'm not anti-vax but the mandate at my job is ridiculous. People are getting fired over this.”와 같은 문장은 접종 의무화로 인한 해고와 불만을 강조하므로 부정(0)으로 라벨링하였다. “Had fever and chills for one night after Moderna, totally worth it if it keeps me out of ICU.”와 같이 부작용 경험을 언급하면서도 전반적으로 접종의 가치를 긍정하는 문장은 긍정(1), “My friend developed heart issues after the shot, doctors keep saying it's unrelated but I'm not convinced.”처럼 심장 질환과 백신의 연관성을 의심하며 불신을 나타내는 문장은 부정(0)으로 라벨링하였다.

감성 분석 모델은 여러 BERT 계열 모델을 비교한 끝에 DeBERTa v3 기반 Binary 분류 모델을 최종적으로 채택하였다. Baseline으로는 Multilingual BERT 등을 실험하였고, 한국어 데이터를 확장하는 데에는 KoELECTRA를 별도로 활용하였다. DeBERTa v3 모델은 CrossEntropy Loss와 클래스 불균형을 보정하기 위한 class weight를 사용해 학습하였고, 옵티마이저는 AdamW를 사용하였다. Early Stopping은 검증 손실과 정확도를 기준으로 3~5 epoch 구간에서 종료하도록 설정하였다.

Epoch별 학습 곡선을 시각화하면 다음과 같다.

![DeBERTa 학습 곡선](images/deberta_epoch_acc_loss.png)

대표적인 학습 로그는 다음 표와 같다.

| Epoch | Train Loss | Train Acc | Val Acc |
|-------|-----------:|----------:|--------:|
| 1     | 0.26       | 0.51      | 0.18    |
| 2     | 0.12       | 0.80      | 0.81    |
| 3     | 0.05       | 0.96      | 0.87    |
| 4     | 0.03       | 0.98      | 0.84    |
| 5     | 0.02       | 0.99      | 0.87    |

초기 epoch에서는 모델이 기본적인 패턴을 빠르게 학습하면서 검증 정확도가 0.18에서 0.81로 급상승한다. 3 epoch에서는 학습 정확도가 약 0.96, 검증 정확도가 약 0.87로 가장 안정적인 일반화 성능을 보인다. 4 epoch에서는 학습 정확도는 계속 상승하지만 검증 정확도가 0.84로 다소 떨어지며 과적합 신호가 관찰된다. 5 epoch에서는 학습 정확도가 0.99, 검증 정확도가 0.87로 수치상 3 epoch와 비슷하지만, 라벨 노이즈와 특정 표현에 대한 과적합 위험이 커질 수 있다. 이러한 이유로 3~5 epoch 구간을 Early Stopping 후보 범위로 설정하고, 성능과 해석의 일관성을 함께 고려하여 현재의 DeBERTa v3 Binary 모델을 최종 모델로 선택하였다.

---

## 5. EDA 및 시계열 분석

DeBERTa v3 Binary 모델을 전체 데이터에 적용한 뒤, 사이트별 감성 분포를 비교하고 시간에 따른 부정 비율 변화를 시계열로 분석하였다. 사이트별 부정·긍정 비율을 비교한 결과, Reddit에서는 정치·사회 이슈와 결합된 논쟁이 많기 때문에 부정 비율이 상대적으로 높은 경향을 보였다. Drugs.com에서는 개인 경험과 “다시 맞을 의향이 있는지”에 초점을 둔 리뷰가 많아 긍정 비율이 상대적으로 높게 나타났다. WebMD와 HealthBoards에서는 건강 상태와 가족 상황을 포함한 고민 글이 많아 불안과 우려를 담은 부정 문장이 눈에 띄었다.

사이트별 감성 분포는 다음 그림과 같이 나타난다.

![사이트별 감성 분포](images/site_sentiment_distribution.png)

작성 날짜를 기준으로 부정 비율의 시계열을 계산한 결과, 특정 시점 이후 부정 비율이 급격하게 상승하는 구간이 관찰되었다. 예를 들어 백신 승인, 특정 부작용 관련 기사, 접종 의무화 정책 발표와 같은 사건 이후에 부정 비율이 일시적으로 급증하는 패턴이 나타났다. 반면 대규모 접종 완료 이후에는 전반적인 부정 비율이 완만해지는 구간도 관찰되었다.

부정 비율의 시계열은 다음과 같이 시각화하였다.

![부정 비율 시계열](images/neg_ratio_timeseries.png)

또한 외부 지표인 Fear & Greed Index를 `FEAR_INDEX.csv`에서 불러와 부정 비율 시계열과 날짜 기준으로 병합한 뒤, 상관 분석과 Dynamic Time Warping(DTW)을 이용한 유사도 분석을 수행하였다. 공포 지수가 극단적으로 높아지는 구간에서 백신 관련 부정 비율도 함께 상승하는 경향이 관찰되었지만, 두 시계열이 완전히 동일하게 움직이기보다는 특정 사건 이후 단기적인 스파이크가 더 잘 드러났다. 단순 상관계수 하나로 요약하기에는 한계가 있어, 시간 지연(lag)을 고려할 수 있는 DTW 기반 비교가 더 적절한 도구로 보였다.

Fear & Greed Index와 부정 비율의 관계는 다음 그림과 같이 정리하였다.

![부정 비율 vs Fear Index](images/neg_ratio_vs_fear_index.png)

---

## 6. 토픽 모델링

토픽 모델링 단계에서는 먼저 LDA를 이용해 전체 이슈 지형의 윤곽을 파악한 뒤, 보다 정교한 분석을 위해 BERTopic과 HDBSCAN 조합을 사용하였다. LDA는 Bag-of-Words 기반 벡터화와 사전 정의한 토픽 개수를 바탕으로 토픽별 상위 단어 리스트를 제공해 주기 때문에 대략적인 주제 분포를 확인하는 데는 유용했다. 그러나 전처리가 조금만 부족해도 URL과 정치인 이름, 사이트 도메인명이 섞인 가비지 토픽이 쉽게 등장한다는 한계가 있었다.

이에 비해 BERTopic은 문장 임베딩과 밀도 기반 클러스터링을 결합하여 보다 의미 단위에 가까운 토픽을 구성할 수 있었다. 전처리와 주제 필터링을 거친 텍스트에 대해 문장 임베딩 모델을 적용해 벡터를 생성하고, HDBSCAN으로 밀도 기반 클러스터링을 수행하였다. 각 클러스터에 대해 대표 단어와 대표 문장을 추출하고, 사람이 직접 읽고 해석 가능한 토픽 이름을 부여하였다. 밀도가 낮은 문서는 자동으로 노이즈 토픽(Topic = -1)으로 분리되어 의미 없는 집합이 정리되었다.

BERTopic 결과를 시각화한 토픽 맵과 바 차트는 다음과 같다.

![BERTopic 토픽맵](images/bertopic_topicmap.png)

부정 리뷰 쪽 상위 토픽을 요약하면 병원과 의료비, 시스템에 대한 불만, 직장에서의 접종 의무와 해고 문제, 부작용과 심근염·혈전 의심 사례, 음모론과 정부/제약사 불신 등으로 정리할 수 있었다. 각 토픽에 DeBERTa Binary 감성 라벨을 결합해 보면 접종 의무화와 해고, 부작용과 후유증 의심, 의료비와 병원 시스템 불만과 관련된 토픽에서는 부정 비율이 특히 높게 나타났고, 감염 대비 경미한 증상이나 가족 보호를 위한 접종과 관련된 토픽에서는 긍정 비율이 상대적으로 높게 나타났다. 이를 통해 어떤 이슈가 백신에 대한 부정 정서를 주로 끌어올리는지 구조적으로 파악할 수 있었다.

---

## 7. 프로젝트 파이프라인 및 코드 구조

프로젝트 전체 파이프라인을 다시 정리하면, 여러 사이트에서 댓글과 리뷰를 크롤링한 뒤, 구조적 노이즈 제거와 언어 필터링, 형식적 노이즈 제거를 거쳐 코로나/백신 키워드 기반 주제 관련성 필터링을 수행하였다. 이후 링크 공유나 정보 전달 위주의 문장을 추가로 제거하고, 일부 문장에 대해 수동 라벨링을 진행하였다. 수동 라벨링 데이터로 DeBERTa v3 Binary 감성 분류 모델을 학습한 뒤, 전체 데이터에 대한 감성 예측을 수행하고, BERTopic을 이용해 토픽 모델을 구축하였다. 마지막으로 토픽과 감성 정보를 결합해 어떤 이슈가 어떤 방향의 감성과 결합하는지 분석하고 시각화하였다.

텍스트 처리 파이프라인의 스냅샷은 다음과 같다.

![텍스트 파이프라인](images/text_pipeline.png)

실제 코드와 데이터는 다음과 같은 디렉터리 구조로 정리하였다.

```text
project-root/
├─ data/
│  ├─ raw/                # 크롤링 직후 원본 데이터
│  ├─ interim/            # 중간 전처리 결과
│  └─ processed/          # 최종 분석용 CSV (DDDD.csv 등)
│
├─ src/
│  ├─ crawling/
│  │  ├─ reddit_crawler.py
│  │  ├─ webmd_crawler.py
│  │  └─ drugs_crawler.py
│  ├─ preprocessing/
│  │  └─ preprocess_pipeline.py
│  ├─ modeling/
│  │  ├─ train_deberta_binary.py
│  │  └─ inference_deberta_binary.py
│  └─ topic_modeling/
│     └─ topic_bertopic.py
│
├─ notebooks/
│  ├─ 01_eda.ipynb
│  ├─ 02_fear_index_analysis.ipynb
│  └─ 03_topic_visualization.ipynb
```

## 8. 한계 및 향후 과제

이 프로젝트는 여러 사이트에 흩어져 있는 백신 관련 댓글과 리뷰를 통합하고, 주제 관련성이 높은 문장만 남긴 고순도 데이터셋을 구축한 뒤, 수동 라벨링과 DeBERTa v3 Binary 모델, BERTopic을 결합해 백신 논쟁의 감성과 토픽 구조를 함께 분석했다는 점에서 의미가 있다. 백신에 대한 찬반을 판정하거나 특정 입장을 옹호하는 것이 아니라, 온라인 공간에 실제로 존재하는 논쟁 구조를 데이터 관점에서 시각화하고 설명하는 것을 목표로 하였다.

동시에 몇 가지 과제도 남아 있다. 우선 언어와 문화권을 영어권에 한정했다는 점이 한계이므로, 한국어와 일본어 등 비영어권 데이터로 확장하고 KoELECTRA와 같은 한국어 모델과 결합하는 연구가 필요하다. 또한 주요 사건(백신 승인, 접종 중단, 부작용 이슈 보도 등)과 감성·토픽 변화를 시계열로 정교하게 결합하여, 정책과 언론 보도, 여론 간 관계를 더 깊게 분석할 수 있다. 마지막으로 부정 여론이 집중되는 토픽에 대해 어떤 메시지와 정보를 제공해야 신뢰를 회복할 수 있는지, 공중보건 커뮤니케이션 전략과 연계한 후속 연구가 가능하다.

이 프로젝트는 팬데믹 시기에 형성된 백신 논쟁을 한 번 정리해 본 사례이면서, 동시에 앞으로 다른 백신이나 감염병, 건강 관련 정책에 대해서도 유사한 데이터 기반 분석을 확장할 수 있는 출발점이 될 수 있다.

│
└─ README.md
