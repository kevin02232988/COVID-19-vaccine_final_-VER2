![header](https://capsule-render.vercel.app/api?type=soft&color=auto&height=300&section=header&text=vaccine%20Review💉&fontSize=90)

# 🦠 COVID Vaccine Controversy Analysis by BERT/DeBERTa
**온라인 댓글 기반 코로나 백신 여론 분석 프로젝트**

[![Python](https://img.shields.io/badge/Python-3776AB?style=flat-square&logo=Python&logoColor=white)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=flat-square&logo=PyTorch&logoColor=white)](https://pytorch.org/)
[![Hugging Face](https://img.shields.io/badge/Hugging%20Face-FFD21C?style=flat-square&logo=huggingface&logoColor=black)](https://huggingface.co/)
[![Transformers](https://img.shields.io/badge/Transformers-FF9A00?style=flat-square&logo=huggingface&logoColor=white)](https://huggingface.co/docs/transformers/index)
[![DeBERTa v3](https://img.shields.io/badge/DeBERTa%20v3-NLP?style=flat-square&color=0A1F44)](https://huggingface.co/docs/transformers/model_doc/deberta_v2)
[![KoELECTRA](https://img.shields.io/badge/KoELECTRA-Korean%20NLP-blue?style=flat-square)](https://huggingface.co/monologg/koelectra-base-v3-discriminator)
[![BERTopic](https://img.shields.io/badge/BERTopic-Topic%20Modeling-0A1F44?style=flat-square)](https://maartengr.github.io/BERTopic/)
[![HDBSCAN](https://img.shields.io/badge/HDBSCAN-Clustering-FF6F00?style=flat-square)](https://hdbscan.readthedocs.io/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-F7931E?style=flat-square&logo=scikitlearn&logoColor=white)](https://scikit-learn.org/)
[![pandas](https://img.shields.io/badge/pandas-150458?style=flat-square&logo=pandas&logoColor=white)](https://pandas.pydata.org/)
[![NumPy](https://img.shields.io/badge/NumPy-013243?style=flat-square&logo=numpy&logoColor=white)](https://numpy.org/)
[![Matplotlib](https://img.shields.io/badge/Matplotlib-11557c?style=flat-square&logo=Matplotlib&logoColor=white)](https://matplotlib.org/)
[![Jupyter](https://img.shields.io/badge/Jupyter-F37626?style=flat-square&logo=Jupyter&logoColor=white)](https://jupyter.org/)

---

## 1. 연구 개요 (Overview)

### 1.1 왜 “백신 논란 댓글”을 주제로 선택했는가?

크게 네 가지 이유가 있다.

- **첫째**, 필자는 경험적으로 “백신”을 신뢰한다. 실제로 대한민국은 오래전부터 높은 예방접종률을 유지해 왔다. 그럼에도 코로나 팬데믹 기간 동안 **‘백신 부작용’** 과 **‘백신 불신’** 은 온라인에서 가장 격렬하게 논쟁된 주제 중 하나였다. 여기서 질문이 생겼다.  
  → **“정말 백신에 대한 부정적 여론은 사람들이 ‘부작용’을 심각하게 생각해서 나타난 것일까?”**

- **둘째**, 코로나 팬데믹 동안 사람들의 감정과 생각은 뉴스 기사 본문이 아니라 **댓글·포럼·SNS**에 훨씬 더 직접적으로 드러나는 양상을 보였다.  
  → 뉴스 기사: “정책이 발표되었다”는 **사실** 중심  
  → 온라인 댓글: “그래서 나는 **불안/분노/찬성/냉소**를 느낀다”는 **감정과 해석** 중심  

- **셋째**, 필자는 제약회사의 **공정·시장 분석** 분야를 진로로 고려하고 있다. 따라서 “약품(백신)에 대한 온라인 감정과 여론을 **데이터로 계량해 보는 작업**”은, 진로와 직접 연결되는 의미 있는 연구 주제라고 판단했다.

- **넷째**, 학창 시절 코로나19 팬데믹을 겪으며, 수많은 대책과 정책들이 **충분한 데이터에 기반하지 않은 채** 현장과 괴리를 보이고, 그 결과가 **사회적 비용 낭비**로 이어지는 장면을 직접 목격했다.  
  지피지기면 백전불태라는 말이 있듯, **“진짜 이유와 원인”** 을 데이터로 파악하는 것은, 다음 팬데믹 상황에서 우리가 어떤 의사결정과 커뮤니케이션 전략을 선택해야 할지 **미리 설계해 보는 출발점**이 될 수 있다.

요약하면, 이 연구는 단순히 “백신이 위험한가/안전한가”를 묻는 것이 아니라,

> **“사람들은 실제로 어떤 이유 때문에 분노하고, 불안해하며, 백신과 정책을 불신하게 되었는가?”**

를 **온라인 댓글 데이터**를 통해 정량적으로 추적해 보려는 시도이다.

기존 연구들은 주로 **확진자 수, 사망자 수, 금융 지표**처럼  
“숫자로 정리된 지표”와 여론의 상관관계를 다루는 경우가 많다.

하지만 실제 논란의 핵심은 다음과 같은 질문에 더 가깝다.

> 사람들은 **정확히 무엇 때문에** 화가 났고, 불안했을까?  
> 정말로 백신에 대한 반감은 사람들이 일반적으로 떠올리는 **백신 부작용** 때문이었을까?  
> 아니면 **마스크·백신 의무화, 경제적 부담, 정치 갈등** 같은 다른 이유가 더 컸을까?

이 프로젝트는 이러한 질문에 답하기 위해  
**대규모 온라인 댓글 데이터**를 모으고,  
**감성 분석 + 토픽 모델링**을 통해  
“코로나 백신 논란의 중심이 어디에 있었는지”를 추적하며,  
그 결과를 바탕으로 **향후 팬데믹에서 어떤 대응과 정책 커뮤니케이션이 필요한지**를 함께 고민하고자 한다.


---

### 1.2 연구 질문

이 프로젝트는 다음 다섯 가지 질문에 집중한다.

- **Q1.** 코로나/백신 관련 온라인 댓글의**감성 분포(긍·부정)** 는 어떠한가?
- **Q2.** 전체 여론에서 **부정 감성의 비중은 얼마나 높은가?**
- **Q3.** 부정/긍정 댓글은 각각 **어떤 주제(토픽)** 를 중심으로 모이는가?
- **Q4.** 시계열에 따라 부정/긍정 댓글은 각각 **어떤 주제(토픽)** 은 어떻게 변하는가?
- **Q5.** 논란의 중심축은
  - **부작용·의학적 위험**인가,  
  - 아니면 **다른 무언가가**인가?

---

## 2. 데이터 수집 (Data Collection)

### 2.1 수집 대상 사이트 & 키워드

크롤링은 **“코로나/백신 논의를 실제로 볼 수 있는 공간”** 에 집중했다.

| 구분 | 플랫폼/사이트 | 언어 | 주요 수집 대상 | 크롤링 방식 / 키워드 예시 |
|------|---------------|------|----------------|----------------------------|
| 커뮤니티 | Reddit (여러 서브레딧) | 🇺🇸 | 게시글/댓글 | `covid`, `vaccine`, `pfizer`, `moderna`, `jab`, `side effect` 등으로 제목/본문 검색 후 댓글 수집 |
| 헬스 포럼 | WebMD, HealthBoards, Patient.info 등 | 🇺🇸 | 증상/부작용 관련 게시글·댓글 | `vaccine`, `shot`, `reaction`, `booster`, `symptoms` 등 키워드 기반 포럼 글/댓글 수집 |
| 약 리뷰 | Drugs.com 등 | 🇺🇸 | 백신·약물 리뷰 | 약 이름 + `covid`, `vaccine` 등 조합으로 리뷰 검색 |
| 국내 Q&A/커뮤니티(실험) | Naver 지식iN, DC Inside 등 | 🇰🇷 | 관련 질문/게시글 | `백신`, `코로나`, `부작용`, `타이레놀` 등으로 크롤링 시도 (최종 분석에서는 대부분 제외) |

- Reddit + WebMD + Pushshift + HealthBoards + Patient.info + Drugs.com 통합
- 최종 영어 데이터: **98,278건**

> 최종 분석은 **언어적 일관성**을 위해  
> **영어 텍스트 중심 데이터셋**을 사용했다. (언어 혼재 문제)



### 2.2 데이터 출처 비율 (Source Distribution)

본 연구에서 사용한 **수량 보정 기준 데이터셋**은 총 **98,278건**으로,  
각 사이트/플랫폼별 문서 수와 비율은 다음과 같다.

| 출처 (Source)          |  건수 (최종)       | 비율 (Percentage) |
|------------------------|-------------------:|------------------:|
| Reddit API (PRAW)      | 73,934             | 75.23%            |
| WebMD                  | 17,055             | 17.35%            |
| HealthBoards           | 3,147              | 3.20%             |
| Pushshift API (Reddit) | 2,132              | 2.17%             |
| Drugs.com              | 1,523              | 1.55%             |
| Patient.info           | 487                | 0.50%             |
| **합계 (Total)**       | **98,278**         | **100.00%**       |



- Reddit 계열 데이터(PRAW + Pushshift)가 전체의 **약 75.23%** 를 차지해  
  영어권 커뮤니티 중심의 논의를 반영하고,
- WebMD, HealthBoards, Patient.info, Drugs.com 등 **헬스 포럼·약 리뷰 사이트 데이터**가  
  나머지 약 24.77%를 구성하여, **임상 경험·부작용 후기** 관점을 보완한다.



![플랫폼 비율 파이 차트](image/Reddit.png)

---



### 2.3 크롤링 기간 (Crawling Window)

본 연구는 우연히 남아 있는 데이터 시점을 그대로 쓰기보다,  
**“코로나 팬데믹 전–확산기–백신 도입·의무화 논쟁기–완화기”** 를 한 흐름으로 보기 위해  
분석 기간을 의도적으로 다음과 같이 잡았다.

- **분석 대상 기간:** 2019년 4월 ~ 2025년 10월

이 기간을 선택한 이유는 다음과 같다.

1. **팬데믹 직전의 기준선(baseline) 확보**  
   - 2019년 상반기 데이터를 포함하여,  
     코로나 이전에 백신·감염병이 어떻게 이야기되었는지 **배경 잡음 수준**을 본다.

2. **팬데믹 선언 및 초기 충격 구간 포함**  
   - 2020년 이후 확진·사망 증가, 봉쇄·락다운, 초기 공포가  
     온라인 댓글에 어떻게 반영되는지 시계열로 관찰하기 위함이다.

3. **백신 도입·의무화 논쟁 전 과정 관찰**  
   - 2020년 말부터 2021년 초의 **백신 도입/접종 시작**,  
     이후 **마스크·백신 의무화, 백신 패스, 직장·학교 규정**이  
     부정 여론과 토픽 구조에 어떤 영향을 주는지 보기 위해  
     2021~2022년 전 기간을 포함했다.

4. **규제 완화 이후에도 남는 잔존 논쟁 파악**  
   - 2023년 이후 규제가 완화된 뒤에도  
     **부작용 논쟁, 장기 후유증, 음모론, 아동 접종 논쟁**이  
     얼마나 오래 남는지를 확인하기 위해 2025년까지의 데이터를 포함했다.

즉, 본 연구의 시계열 분석은  
**“팬데믹 전 → 충격기 → 백신 도입·의무화 갈등기 → 규제 완화 이후까지”**  
온라인 여론이 어떻게 이동하는지를 보기 위해 2019-04 ~ 2025-10 으로 기간을 설정한 것이다.

---

### 2.4 Reddit 데이터 수집 개요 및 수집 전

Reddit는 **게시글–상위 댓글–대댓글** 구조를 가지는 대표적인 코로나/백신 논쟁 공간이기 때문에,  
본 프로젝트에서는 다음 기준으로 데이터를 수집했다.

- **타깃 서브레딧**
  - 코로나/백신 관련 논의가 활발한 서브레딧 여러 개를 사전에 선정  
    (예: `r/Coronavirus`, `r/COVID19`, `r/CoronavirusUS`, `r/CoronavirusVaccine`, `r/antiVaccine` 등)

- **게시글 선택 기준**
  - 각 서브레딧에서 `subreddit.top(time_filter="all")`을 사용해  
    **팬데믹 전후 전체 기간에서 이슈를 대표하는 상위(top) 게시글**들만 가져옴
  - 별도의 날짜 필터는 두지 않고, 이후 통합 시 `created_at` 시계열(2019-04 ~ 2025-10)로 정리

- **댓글 단위 수집 기준**
  - 선택된 각 게시글에 대해 **전체 댓글 트리(상위 댓글 + 대댓글)** 를 모두 펼쳐서 수집
  - 각 댓글마다 `body`, `created_utc`, `score`, `subreddit`, `post_id`, `comment_id`, `parent_id` 등을 저장
  - 크롤링 단계에서 최소한의 필터만 적용:
    - `"[deleted]"`, `"[removed]"` 본문 제거  
    - 공백 제거 후 20자 미만의 **너무 짧은 잡담(lol, ok, 이모티콘 한 줄 등)** 제거

- **시계열 정리**
  - Reddit 원본의 `created_utc`(UTC 타임스탬프)를 공통 `created_at`(datetime) 컬럼으로 변환해 정리하였다.

> Reddit 크롤링 코드(PRAW 설정, 댓글 트리 평탄화 로직 등)와  
> 더 상세한 구현 과정은 **부록 8.7 – Reddit 크롤링 세부 전략**에 정리했다.


---

### 2.5 원시 댓글 데이터 예시 (Raw Samples)


| source         | created_at        | text (원문 일부) | 원문 링크 (URL) |
|----------------|-------------------|------------------|------------------|
| `Reddit`       | 2021-01-15 13:24  | "I got my second Pfizer shot yesterday and my arm hurts like hell, but honestly it's nothing compared to getting covid. My parents are getting theirs next week..." | [원문 링크](https://www.reddit.com/r/TrueUnpopularOpinion/comments/1o9kdat/modern_covid_vaccines_were_not_safe_and_effective/) |
| `WebMD`        | 2021-03-02 08:11  | "After the Moderna vaccine I had chills and a fever for one night. I was scared because of all the news, but my doctor said it was a normal immune response..." | [원문 링크](https://www.healthboards.com/boards/search_google.php?cx=partner-pub-8247140117206678%3A125c5bc0u3i&cof=FORID%3A11&ie=UTF-8&q=covid+vaccine&sa=search) |
| `HealthBoards` | 2020-11-28 21:03  | "My mom is in the hospital and they're talking about this new vaccine. I'm worried about long term side effects, but also about her catching covid while waiting..." | [원문 링크](https://www.webmd.com/vaccines/covid-19-vaccine/default.htm) |
| `Drugs.com`    | 2021-05-07 17:40  | "Vaccine: [brand]. Age: 35. Side effects: sore arm, mild headache, fatigue for 2 days. Would still recommend, it's better than the risks of covid." | [원문 링크](https://www.drugs.com/comments/covid-19-mrna-moderna-vaccine/) |





## 3. 데이터 전처리

### 3.1 전처리 파이프라인

전처리는 크게 네 단계로 구성된다.

1. **구조적 노이즈 제거**
   - `[deleted]`, `[No Content]` 등 삭제된 게시물 제거  
   - `lol`, `ok`처럼 **20자 미만**, **5단어 미만**의 의미 없는 짧은 문장 삭제

2. **언어 필터링**
   - 비영어 문자 비율이 **일정 기준 이상**인 문장 제거  
   - 영어 기반 사전학습 모델 사용을 고려한 일관성 확보

3. **형식적 노이즈 제거**
   - URL, 특수문자, 이모티콘 등 제거

4. **주제 관련성 필터링 (Keyword-based Relevance)**
   - 아래와 같은 코로나/백신 핵심 키워드 중  
     **하나도 포함되지 않은 문장은 “주제 무관”으로 제거**

   ```python
   KEYWORDS = [
       'vaccine', 'covid', 'coronavirus', 'side effect', 'adverse', 'pfizer', 'moderna',
       'booster', 'jab', 'shot', 'vax', 'myocarditis', 'astrazeneca', 'janssen',
       'symptoms', 'mandate', 'mask', 'masked', 'unvaccinated', 'vaxxed', 'unvaxxed',
       'hospital', 'death', 'long covid', 'long-covid', 'spike protein', 'mrna'
   ]
   ```

 → 전처리의 핵심은 “양을 줄이더라도, 코로나/백신 논쟁에 실제로 해당하는 문장만 남기자”는 원칙으로 진행했다.

---

### 3.1.1 전처리 버전 비교

실제 구현 과정에서는 아래와 같이 여러 버전을 거쳐 강화되었다.(부록 참조)

#### 버전 A – 최소 전처리

- 특수문자·이모티콘 제거 + 소문자 변환 정도만 수행
- LDA 상위 키워드에 `http`, `www`, `com`, `trump`, `biden`, `news` 등  
  링크/정치인/사이트 이름이 과도하게 등장, 여전히 코로나/백신과 **직접 관련 없는 잡담**이 다수 포함  
  → **주제 관련성 필터링 단계 추가 필요**
  → **“이 정도로는 ‘백신 논란의 구조’를 보기 어렵다”** 는 결론


#### 버전 B – 키워드 기반 주제 관련성 필터링

- 코로나/백신 이슈에서 실제로 자주 등장하는 키워드 리스트 구축
- 문장 내에 이 키워드가 **하나도 없으면 “주제 무관(False)”로 제거**
- 슬슬 `mask`, `vaccine`, `company`, `money`, `hospital` 등 의미 있는 단어가 LDA 토픽에 등장하기 시작

→ 최종 파이프라인은 이 **버전 B**를 기반으로 구축되었으며,  
전처리의 목적은 **“텍스트를 깨끗하게 만드는 것 + 주제와 무관한 문장을 제거하는 것”**  
두 축을 동시에 만족하는 것이었다.

**결과:**

- ✅ True (관련 있음): **23,939건**  
- ❌ False (관련 없음): **75,338건** (분석 제외)

True 데이터 10%를 직접 검토한 결과,

- 대부분 실제로 코로나/백신 논의
- 단, 남은 True 데이터 중 링크 공유·정보 전달 위주로 감정이 거의 없는 문장은 추가로 삭제했다
  약 **1,010개 행 삭제** → `FINAL_DATA_ROWS_DELETED.csv` 저장
- 이 중 링크를 공유하면서 감정이 있는 데이터 **423개는 복구**를 진행했다. →  
  `FINAL_DATA_ROWS_DELETED_2.csv` (약 23,352건) 생성  

---

#### 3.1.2 전처리 단계별 실제 예시

아래는 Reddit에서 가져온 실제 댓글 한 문장이  
전처리 단계(A→B→C)를 거치며 어떻게 정제되는지 보여주는 예시이다.

| 단계 | 내용 |
|------|------|
| Raw 원문 | "Here's the link to the article about covid vaccines: https://[...] Honestly I'm scared of the side effects, but also I don't want my dad to end up in the hospital again." |
| A. 최소 전처리 | "heres the link to the article about covid vaccines https honestly im scared of the side effects but also i dont want my dad to end up in the hospital again" |
| B. 키워드 기반 관련성 필터 통과 여부 | ✅ `covid`, `vaccines`, `side effects`, `hospital` 포함 → **주제 관련 (True)** 으로 유지 |

> 이처럼 전처리에서는  
> - **형식적 노이즈 제거(A)** 와  
> - **코로나/백신 관련 여부 필터링(B)**  
> 을 동시에 수행해, “깨끗하면서도 주제에 맞는 텍스트”만 남기도록 했다.



### 3.1.3 전처리 단계별 데이터 수 변화

| 단계 | 설명 | 남은 데이터 수(건) |
|------|------|--------------------|
| **0. Raw merged** | 여러 사이트에서 크롤링한 뒤, 기본적인 형식 통일만 수행한 상태 | **약 98,278**건 |
| **1. 구조적 노이즈 제거** | `[deleted]`, 너무 짧은 잡담(lol, ok 등), 내용 없는 문장 제거 | 약 90,000 내외 |
| **2. 언어 필터링** | 비영어 텍스트 제거 (비영어 비율이 높은 문장 필터링) | **약 82,000**건 |
| **3. 주제 관련성 필터링** | 코로나/백신 관련 키워드가 **하나도 없는 문장 제거** | ✅ 관련 있음: **23,939**<br>❌ 관련 없음: 75,338 (제외) |
| **4. 링크·정보공유 위주 문장 제거** | 기사/논문 링크만 공유하거나, 의견/감정이 거의 없는 문장 추가 삭제 | **23,352**건 |
| **5. 모델 학습/분석용 최종본** | 날짜/텍스트/사이트 정보가 완비되고, 전처리가 완전히 끝난 데이터 | **20,929**건  |

> **108k → 20,929건**으로 줄어드는 과정에서  
> **“주제와 감정을 갖고 있는 문장”만 최대한 남기도록 설계**했다.  
> 숫자를 줄이는 것이 목표가 아니라,  
> “코로나/백신 논쟁”과 **무관한 잡음을 제거하는 것**이 목표였다.

---


### 3.2 수동 라벨링 데이터

- 전체 데이터 중 **약 10% (2,100개)** 를 무작위로 샘플링
- 사람(연구자)이 직접 **두 가지 라벨**을 동시에 부여
  - Binary: `0 = 부정`, `1 = 긍정`
  - Three-Class: `0 = 부정`, `1 = 중립`, `2 = 긍정`
- 이후 성능·안정성을 고려해  
  최종 파이프라인은 **Binary 분류(부정 vs 긍정)** 에 집중

#### 3.2.1 수동 라벨 예시 (실제 문장 4개, Binary)

아래는 사람이 직접 라벨링한 댓글 예시 4개이다.  

| id  | text (일부) | Binary 라벨 |
|-----|-------------|-------------|
| ex1 | "The vaccine saved my parents. They both caught covid before and this time it was just like a mild cold." | 1 (긍정) |
| ex2 | "I'm not anti-vax but the mandate at my job is ridiculous. People are getting fired over this." | 0 (부정) |
| ex3 | "Had fever and chills for one night after Moderna, totally worth it if it keeps me out of ICU." | 1 (긍정) |
| ex4 | "My friend developed heart issues after the shot, doctors keep saying it's unrelated but I'm not convinced." | 0 (부정) |


### 3.2.2 감성 분석 모델 (Sentiment Classification)

**모델 후보**

- KoELECTRA (한국어, 실험용)
- BERT 계열 (영어, baseline)
- DeBERTa v3 (영어, 최종 선택)

**최종 설정 (요약)**

- **모델:** DeBERTa v3 기반 Binary 분류  
- **학습 데이터:** 약 2100개 수동 라벨링 데이터  
- **손실 함수:** CrossEntropy + 클래스 불균형 대응 (class weight 등)  
- **결과:** Validation Accuracy ≈ **0.86 ~ 0.87**

  #### 3.2.3 최종 학습 스냅샷 

Epoch별 대표 로그는 다음과 같다.

| Epoch | Train Loss | Train Acc | Val Acc |
|-------|-----------:|----------:|--------:|
| 1     | 0.26       | 0.51      | 0.18    |
| 2     | 0.12       | 0.80      | 0.81    |
| 3     | 0.05       | 0.96      | 0.87    |
| 4     | 0.03       | 0.98      | 0.84    |
| 5     | 0.02       | 0.99      | 0.87    |

![Epoch 학습 정확도/ 검증 정확도](image/AA.png)

- Early Stopping 관점에서 **Epoch 3~5 구간이 최적**으로 판단되었다.
- 최종적으로 **Validation Accuracy 약 0.87** 수준의 **DeBERTa 모델**을 채택하였다.

KoELECTRA/Three-Class 등 다양한 시도는  
부록(시행착오 요약)에 정리했다.

---

### 3.3 토픽 모델링 (Topic Modeling)

- **1차:** LDA (Latent Dirichlet Allocation)
  - 전처리 문제와 주요 주제 축(경제·정치·마스크·의료비 등) 파악
- **최종:** BERTopic + HDBSCAN
  - 고차원 임베딩 + 밀도 기반 클러스터링
  - 사람이 읽고 해석 가능한 토픽 이름 수동 부여

감성 라벨(부정/긍정)과 토픽을 결합해

> **“어떤 이슈가 어떤 감성에 연결되는지”** 를 보는 것이 핵심이다.

---

## 4. 주요 결과 (Results)

### 4.1 감성 분포

전체 최종 데이터(20,929건)에 대해  
DeBERTa v3 Binary 모델이 예측한 결과:

| 감성              | 개수   | 비율    |
|-------------------|-------:|--------:|
| 부정 (Negative)   | 18,024 | 약 86%  |
| 긍정 (Positive)   | 2,905  | 약 14%  |

→ 코로나/백신 관련 온라인 댓글은  
전반적으로 **부정 여론이 절대적으로 우세한 구조**를 보인다.

![긍/부정 비율](image/B.png)


---

### 4.2 부정 토픽 요약

부정으로 분류된 댓글(18,024건) 중  
BERTopic으로 뽑은 **대표 토픽 축(요약)** 은 다음과 같다.

| 축 | 대표 내용 (요약) | 예시 키워드 |
|---|------------------|-------------|
| **의료비·의료 시스템 불만** | 병원비, 빚, 의료 접근성, 간호 인력 부족 등 | hospitals, debt, pay, healthcare, nurses |
| **마스크·백신 의무화 갈등** | 상점/직장에서의 마스크와 백신 착용 강제, 고객–직원 갈등 | walmart, store, customers, masks, enforce |
| **정치·책임 공방** | 트럼프, 정부, 누구 책임인가에 대한 논쟁 | trump, president, responsible, politics |
| **백신 부작용·장기 후유증 걱정** | 접종 후 증상, 사망·장기 코로나에 대한 두려움 | effects, infection, long, died, side |
| **아동·취약계층 걱정** | 아이 접종, 소아과, 기저질환자 마스크 착용 문제 | kids, children, parents, asthma, breathing |
| **음모론·hoax 프레이밍** | “covid는 사기다”, “propaganda다”라는 담론 | hoax, propaganda, fake, deny |

**핵심 포인트**

- “백신 부작용”만이 아니라,
- **의료비·병원 시스템**,  
- **마스크/백신 의무화**,  
- **정치적 갈등**,  
- **음모론 프레이밍**이 모두 뒤섞여 **부정 여론을 형성**하고 있다.

---

#### 4.2.1 토픽별 실제 문장 예시

각 토픽이 어떤 식의 문장으로 구성되는지 보여주기 위해,  
토픽별 실제 댓글 예시를 일부 제시한다.

**[토픽: 의료비·의료 시스템 불만]**

> "I avoided going to the hospital when I had covid symptoms because I simply can't afford another bill. The vaccine side effects scare me less than the debt."

**[토픽: 마스크·백신 의무화 갈등]**

> "My store is still forcing masks even after the mandate ended. Customers yell at us, management doesn't care, it's a nightmare."

**[토픽: 음모론·hoax 프레이밍]**

> "Covid is just a hoax to control people, the so-called vaccine is part of the same propaganda machine."

**[토픽: mRNA 백신 옹호·효과]**

> "mRNA vaccines are one of the best things modern medicine has done. My whole family got vaccinated and no one ended up in the hospital this time."


### 4.3 긍정 토픽 요약

긍정 댓글(2,905건)에서 나타난 주요 토픽 축은 다음과 같다.

| 축 | 대표 내용 (요약) | 예시 키워드 |
|---|------------------|-------------|
| **mRNA 백신 옹호·효과** | 효과를 경험했다, 면역이 생겼다 등 | vaccine, vaccinated, mrna, immune |
| **경미한 부작용 경험 공유** | 팔이 아팠지만 괜찮았다, 부작용이 생각보다 약했다 | pfizer, moderna, side, second, dose |
| **의료진·병원의 역할 인정** | 의료진의 희생과 시스템 유지에 대한 감사 | hospital, patients, care, nurses |
| **마스크/규정 준수 긍정** | 마스크 착용이 타인을 보호한다는 인식 | wear, mask, protect, medical |

→ 같은 “병원/마스크/백신”이라도  
어떤 사람에게는 **부정(비용·강제성)**,  
어떤 사람에게는 **긍정(보호·안전)** 으로 받아들여진다는 **여론의 양면성**이 뚜렷하게 드러난다.

---

### 4.4 “논란의 중심”에 대한 정리

아래 그래프는 부정 댓글 중에서 백신 부작용 관련 키워드가 포함된 비율(파란색)과  
그 밖의 기타 이슈 비율(주황색)을 월별로 나타낸 것이다.

![월별 부정 댓글 내 부작용 언급 비율 추이](image/EEE.png)

이 그래프와 앞서의 BERTopic 토픽 결과를 함께 보면, 논란의 중심축은 다음과 같이 **시간에 따라 구조가 이동**하는 경향을 보인다.

- **백신 도입 이전(2019~2020)**  
  - 부정 댓글 중 **부작용 언급 비율은 거의 0에 가깝고**,  
    대부분은 기타 이슈(경제적 피해, 봉쇄·락다운, 정치·정책 갈등 등)에 대한 불만으로 채워져 있다.  
  → 이 시점의 “코로나 논란”은 아직 **백신 자체**보다는 **팬데믹 대응 전반**에 초점이 맞춰져 있다.

- **백신 접종 본격화 시기(2020년 말~2021년 초)**  
  - 부작용 언급 비율이 **일시적으로 0.6~0.7 수준까지 급등**한다.  
  - 실제 댓글에서도 `side effects`, `reaction`, `long term`, `myocarditis` 등  
    **안전성 관련 키워드가 자주 함께 등장**하며,  
    이 시기에는 **“새로운 백신의 부작용·장기 후유증에 대한 불안”** 이 부정 여론의 중요한 축으로 부상했음을 보여준다.

- **그 이후(2022~2025)**  
  - 부작용 언급 비율은 **대략 0.2~0.4 사이에서 등락하며 안정화**되고,  
    나머지 **기타 이슈 비율은 0.6 전후**로 꾸준히 높게 유지된다.  
  - BERTopic 토픽 구조를 함께 보면, 이 “기타 이슈”는 주로  
    - 마스크·백신 **의무화/규정 적용 방식**,  
    - **의료비·병원 시스템**,  
    - **정치적 책임 공방·음모론 프레이밍**  
    과 관련된 토픽으로 구성되어 있다.

정리하면, 본 데이터셋에서 관찰되는 백신 논란은

- **초기에는** “백신 안전성과 부작용”이 부정 여론의 핵심 축 중 하나로 **짧게 급부상**했다가,
- **시간이 지날수록**  
  **마스크·백신 의무화, 의료비 부담, 정치·정책 갈등** 등  
  **백신을 둘러싼 제도와 강제 방식에 대한 불만**이 더 큰 비중을 차지하는 구조로 이동한다.


다시 말해, 논란의 핵심은 단순한  
“백신이 위험하냐, 아니냐”를 넘어서 **백신을 둘러싼 시스템과 강제 방식**에 대한 불만으로 확장되었다고 해석할 수 있다.

---
### 4.5 시계열 그래프와 당시 토픽·정책 이벤트의 결합 해석

아래 **월별 부정 감정 비율 그래프(2019–2025)** 는 
BERTopic으로 얻은 토픽 구조와 실제 코로나 관련 **당시에 정책 이벤트**를 함께 볼 때 더 명확하게 해석할 수 있다.

![시계열에 따른 부정 비율](image/BBB.png)

#### (1) 2020년 초–중반: 초기 팬데믹 & 락다운 국면

- **그래프 특징**  
  - 팬데믹 선언(2020년 3월) 전후로 부정 비율이 높은 수준에서 시작하지만,  
    이후 일시적으로 완만하게 내려가는 구간이 존재.
- **주요 이벤트**  
  - WHO 팬데믹 선언, 각국의 초기 봉쇄·외출 제한, 경제활동 급격한 위축.
- **토픽 연결 (BERTopic)**  
  - 부정 토픽에서 **「정치·책임 공방」**, **「경제적 불안」** 이 서서히 등장.  
  - 확진·사망 증가 뿐 아니라 “누가 책임을 져야 하는가”, “정부 대응이 적절했는가”를 둘러싼 논쟁이 부정 비율을 지지하는 초기 요인으로 작용.

---

#### (2) 2020년 말–2021년 초: 백신 도입 & 초기 접종기

- **그래프 특징**  
  - 부정 감정 비율이 다시 **80–90% 구간으로 급상승**하여 등락이 커지는 시기.
- **주요 이벤트**  
  - 2020년 12월 이후 미국·유럽을 중심으로 **mRNA 백신 긴급사용 승인(Pfizer, Moderna 등)**.  
  - 2021년 초 고위험군·의료진 등에게 접종 확대.
- **토픽 연결 (BERTopic)**  
  - 부정 토픽에서 **「백신 부작용·장기 후유증 걱정」**, **「정치·책임 공방」** 의 비중이 크게 증가.  
  - 실제 댓글 수준에서도 “장기 부작용이 검증되지 않았다”, “문제가 생기면 누가 책임지나”와 같은 문장이 다수 등장하며,  
    **백신 도입 자체가 새로운 부정 요인**으로 반영된 것으로 해석 가능.

---

#### (3) 2021년 중반–2022년: 백신·마스크 의무화 본격화 구간

- **그래프 특징**  
  - 부정 비율이 **80–90% 박스권에서 장기간 고착**되어 쉽게 내려오지 않는,  
    그래프 상 가장 중요한 고점 구간.
- **주요 이벤트**  
  - 여러 국가에서 **직장·공공기관 백신 의무(접종 증명 제출, 백신 패스)** 및  
    **실내 마스크 의무**가 본격적으로 시행·연장.  
  - 일부 지역에서는 미접종자 출근 제한, 시설 출입 제한, 해고 사례 등이 사회적 논쟁으로 부상.
- **토픽 연결 (BERTopic)**  
  - 이 시기 부정 토픽에서
    - **「마스크·백신 의무화 갈등」**,  
    - **「의료비·의료 시스템 불만」**  
    두 축이 함께 강하게 나타난다.
  - “직장에서 백신을 강제로 맞힌다”, “병원비·부작용 치료비를 감당할 수 없다”는 유형의 댓글이 꾸준히 생산되며,  
    **정책의 강제성과 의료비 부담이 부정 비율을 높은 평형 상태로 고정시키는 요인**으로 작용한 것으로 볼 수 있다.

---

#### (4) 2023년 이후: 규제 완화 후에도 남는 잔존 논쟁

- **그래프 특징**  
  - 전체 수준은 약간 완화되지만, 여전히 **70–90% 사이의 높은 부정 비율**이 유지.
- **주요 이벤트**  
  - 2023년 WHO의 공중보건 비상사태 종료 선언, 다수 국가에서 방역 규제·의무화 완화.  
  - 그럼에도 백신 후유증 논쟁, 장기 코로나(long COVID), 아동·청소년 접종 문제는 계속해서 온라인에서 논의됨.
- **토픽 연결 (BERTopic)**  
  - 부정 토픽에서
    - **「아동·취약계층 걱정」**,  
    - **「음모론·hoax 프레이밍」**  
    이 장기적으로 남아 있는 양상이 관찰된다.
  - “아이에게 맞혀도 되는가”와 같은 보호자 관점의 우려,  
    “covid는 결국 정치적 사기였다”는 식의 음모론 댓글이  
    **팬데믹 이후에도 부정 비율이 50% 이하로 내려가지 않는 원인**으로 작동한다.

---

#### 4.5.1 요약: 시계열 × 토픽 × 이벤트가 보여주는 논란의 이동

> 월별 부정 감정 비율을 실제 시기별 정책 이벤트와 BERTopic 토픽 구조와 함께 보면,  
> **초기 팬데믹 단계에서는 감염·봉쇄·정치적 책임을 둘러싼 논쟁이 부정 여론의 주요 요인이었으나,  
> 2021년 이후에는 백신·마스크 의무화와 의료비 부담 토픽이 부정 여론의 중심축으로 대체**되었음을 확인할 수 있다.  
> 팬데믹 종료 이후에도 아동·취약계층 걱정과 음모론 토픽이 장기적으로 남으면서,  
> 부정 비율이 완전히 50% 이하로 떨어지지 않는 구조가 유지된다.


---

## 5. 논의 (Discussion)

### 5.1 공중보건 커뮤니케이션 관점

이 분석은 부정 감성이  
**“부작용 자체”보다 “정책·의무화·경제·정치 갈등”** 에 더 민감하다는 점을 시사한다.

향후 팬데믹 대응에서

- “백신은 안전하다”는 메시지 **하나만으로는 부족**하며,
- 동시에 다음 내용을 함께 설명하는 전략이 필요하다.

1. **정책의 공정성**
   - 누구에게 어떤 기준으로 적용되는지
2. **강제성의 한계와 예외 규정**
   - 건강상 사유, 직업적 특성 등에 따른 예외
3. **보상 구조**
   - 부작용 발생 시 지원, 생계 보장 등
4. **정책 결정 과정의 투명성**
   - 어떤 데이터와 전문가 의견을 바탕으로 결정했는지

---


### 5.2 의료 정책·의료기관 관점

부정 토픽에서 지속적으로 등장한 키워드:

- 병원(**hospital**)
- 빚(**debt**), 비용(**pay**)
- 간호 인력 부족(**nurses**)

→ 백신 논란은 단순히  
“맞을까, 말까”를 넘어서

> **“이 시스템 안에서 아프면 나는 얼마나 비용을 지게 되는가?”**

라는 질문과 결합되어 있음.

정책적으로는

- **무료 접종**
- **보험 적용 범위**
- **의료비 지원**
- **상담 창구 안내**

같은 정보를 **적극적으로 알리는 것 자체**가  
부정 여론 완화에 중요할 수 있다.

---

### 5.3 정보 플랫폼·언론·팩트체크 관점

부정 토픽 중 **“covid hoax / propaganda / 음모론”** 토픽은  
상당히 또렷한 클러스터로 분리되었다.

이를 활용하면:

1. 특정 키워드/프레이밍  
   (예: `hoax`, `fake`, `plandemic` 등)의  
   등장 빈도와 맥락을 **상시 모니터링**하고,
2. 해당 프레이밍이 급증하는 시점에
   - **팩트체크 콘텐츠 노출 강화**
   - **공신력 있는 설명글 상단 고정**
   - **추천 알고리즘 조정**

같은 **조기 개입 전략**을 설계할 수 있다.

---

## 6. 결론 (Conclusion)

이 연구는 단순히  
> “백신이 위험한가, 안전한가?”  

를 묻는 대신,

> “사람들은 **정확히 무엇 때문에** 분노하고, 불안해하며,  
>  백신과 방역 정책을 불신하게 되었는가?”  

를 알고 싶다는 질문에서 출발했다.  

이를 위해 2019년 팬데믹 이전부터 2025년까지의 온라인 댓글 약 10만 건을 모으고,  
전처리·감성 분석(DeBERTa v3)·BERTopic 토픽 모델링을 결합해  
**코로나 백신 논란의 구조와 시계열 변화를 데이터로 재구성**하고자 했다.

그 결과, 다음과 같은 결론에 도달했다.

1. **온라인 백신 담론의 “기본값”은 전 기간에 걸쳐 부정이었다.**  
   - 최종 데이터 20,929건 중 **약 86%가 부정**, 14%만이 긍정으로 분류되었다.  
   - 코로나/백신을 다루는 온라인 공간은 처음부터 끝까지  
     “조금 부정이 많은 정도”가 아니라 **뚜렷한 음수 편향을 가진 공간** 에 가까웠다.

2. **초기 짧은 구간에서는 ‘새 백신의 부작용·장기 후유증’이 실제로 핵심 논란이었다.**  
   - 백신 도입 직후(2020년부터 2021년 초) 부정 댓글 중  
     **부작용 언급 비율이 0.6에서 0.7까지 급등**했다.  
   - `side effects`, `reaction`, `long term`, `myocarditis` 같은 키워드가 토픽 상위에 올랐고,  
     이 시기만 놓고 보면 사람들은 “몸에 대한 직접적인 위험”에 크게 반응하고 있었다.

3. **그러나 장기적으로 부정 여론의 중심축은 ‘백신 자체’에서 ‘시스템과 제도’로 이동했다.**  
   - 2022년 이후에는 부작용 언급 비율이 **0.2~0.4에서 안정화**되는 반면,  
     나머지 **기타 이슈(0.6 전후)** 가 꾸준히 높은 비중을 유지했다.  
   - BERTopic 결과를 함께 보면 이 “기타 이슈”는  
     - 마스크·백신 **의무화 및 직장·상점 규정 적용 방식**,  
     - **의료비·병원 시스템과 빚·비용 부담**,  
     - **정치적 책임 공방과 ‘covid hoax/propaganda’ 프레이밍**  
     으로 구성된다.  
   - 즉, 시간이 지날수록 논쟁의 초점은  
     **“무엇을 맞느냐”가 아니라 “어떻게 강제되고, 그 비용과 책임을 누가 지느냐”** 로 이동했다.

4. **따라서 ‘백신 반감 = 부작용 공포’라는 단순한 프레임은 현실을 설명하기에 부족하다.**  
   - 이 데이터셋에서 관찰된 백신 논란은  
     - 초반에는 **새로운 백신의 안전성에 대한 불안**,  
     - 이후에는 **제도·의무화·경제·정치 갈등이 얽힌 시스템 문제**가 중심을 차지하는  
       **2단계 구조**를 보였다.  
   - “부작용을 줄이면 백신 논란이 사라질 것”이라는 가정은,  
     적어도 온라인 댓글 세계에서는 성립하지 않는다.  
     논란의 상당 부분은 **정책 설계와 커뮤니케이션 방식**에 의해 유지·재생산되고 있었다.

---

이 결과는 **연구자 개인**에게도, **사회 전체**에도 다음과 같은 의미를 가진다.

### (1) 연구자(필자)에게의 의미

- 제약회사 **공정·시장 분석**을 꿈꾸는 사람으로서,  
  백신·약품에 대한 시장 반응을 볼 때  
  **“효능/안전성 지표만이 아니라, 정책·비용·책임 구조까지 함께 읽어야 한다”** 는 교훈을 얻었다.
- 같은 백신이라도  
  - 어떤 가격과 보상 체계 위에서,  
  - 어떤 의무화 방식과 예외 규정을 두고,  
  - 어떤 정치·미디어 환경 속에서 도입되는지에 따라  
  **완전히 다른 여론 구조**가 형성될 수 있다는 것을 확인했다.

### (2) 사회·정책적 의미

- 향후 팬데믹에서 “백신은 안전하다”는 메시지 하나만으로는 부족하다.  
- 공중보건 커뮤니케이션은 다음 요소에 대한 설명을 함께 포함해야 한다.
  - **정책의 공정성**
  - **강제성의 한계와 예외 규정**
  - **부작용 발생 시 보상·지원 구조**
  - **정책 결정 과정의 투명성**
- 또한 정보 플랫폼과 언론은  
  **음모론·hoax 프레이밍 토픽을 조기 포착하고 개입할 수 있는 모니터링 체계**를  
  기술적으로 구축해야 한다는 함의를 제공한다.

---

요약하면,  
이 프로젝트는 **“백신이 위험하냐, 아니냐”라는 이분법을 넘어**,  

> 사람들의 분노와 불신이 실제로는  
> **백신을 둘러싼 시스템, 강제 방식, 비용과 책임의 배분 구조**에 더 민감하게 반응한다는 것

을 온라인 댓글 데이터로 보여주고자 했다.  

다음 팬데믹에서 우리가 더 나은 결정을 내리기 위해서는,  
**약의 효과와 안전성**을 검증하는 작업과 더불어,  
**그 약을 둘러싼 제도와 커뮤니케이션의 설계** 자체를  
동일한 수준의 데이터와 진지함으로 다뤄야 한다는 점을  
이 연구가 작은 출발점으로 제시했다고 생각한다.

---


## 7. 한계 및 향후 과제

### 7.1 한계

1. **모델 성능의 한계**
   - Validation Accuracy ≈ **0.87** 수준으로 나쁘진 않지만,
   - 라벨링 오차, 미세한 뉘앙스 오분류 가능성 존재

2. **데이터 편향**
   - Reddit/영어권 포럼 비중이 높아  
     특정 국가·문화·정치 환경에 치우친 여론을 반영

3. **중립 감성 구분의 어려움**
   - Three-Class 모델에서는 **중립 클래스 분리**가 매우 어려웠고,
   - 최종적으로 **Binary 분류**에 집중하게 됨

---

### 7.2 향후 과제

1. **모델 고도화**
   - RoBERTa, GPT 계열 등 다른 아키텍처와 비교
   - 감성 + 토픽/속성 동시 예측하는 **Multi-task 학습** 시도

2. **Relevance 필터 자동화**
   - 키워드 기반 필터 대신  
     별도의 **주제 관련성 분류기(ML 모델)** 도입

3. **다국어·다지역 확장**
   - 한국/유럽/기타 지역 포럼을 추가해  
     국가별 백신 논란 패턴 비교

4. **실시간 대시보드화**
   - 감성·토픽 흐름을 실시간으로 시각화하는  
     **온라인 여론 모니터링 시스템**으로 확장

---

## 8. 데이터 / 폴더 구조 (Data & Folder Layout)

### 8.1 주요 CSV 파일 설명

```text
data/
├─ raw/                     # 크롤링 직후 또는 최소 전처리 상태의 원본 데이터
│   ├─ FINAL_DATA_CLEANED_READY.csv
│   ├─ FEAR_raw.csv / FEAR_source.csv   # (옵션) 공포지수 원본
│   └─ ... (개별 사이트별 원본 CSV들)
│
├─ interim/                 # 중간 전처리/필터링 결과
│   ├─ FINAL_DATA_FILTERED_#TRUE.csv
│   │   # is_related_topic = True 인 코로나/백신 관련 텍스트만 남긴 버전
│   ├─ FINAL_DATA_FILTERED_#FALSE.csv
│   │   # 관련성이 낮아 제거된 텍스트 (분석에는 사용 X, 검증용으로 보관)
│   ├─ FINAL_DATA_ROWS_#DELETED.csv
│   │   # 링크 공유 위주·의견/감정이 거의 없는 중립 문장 추가 삭제본
│   └─ ... (필요한 중간 버전들)
│
├─ processed/               # 분석/모델 학습에 사용되는 최종본
│   ├─ DDDD.csv
│   │   # 최종 분석용 메인 데이터셋
│   │   # (정제 완료 텍스트 + 날짜 + 사이트 정보 + 모델 예측 감성 등)
│   ├─ labeled_output#.csv
│   │   # 전체 데이터의 약 10% 샘플에 대해
│   │   # 사람이 직접 Binary/Three-Class 감성 라벨을 붙인 결과
│   ├─ 10_per#_final.csv
│   │   # 수동 라벨링 정제본 (학습/검증에 실제 사용한 버전)
│   └─ ... (토픽모델링/시계열용으로 가공된 추가 CSV가 있다면 여기에)
│
└─ external/                # 외부 지표/보조 데이터
    ├─ FEAR#.csv
    │   # 공포·탐욕 지수(Fear-Greed Index) 시계열
    │   # 날짜(date) 기준으로 DDDD.csv의 부정 비율과 merge해서 사용
    └─ ... (향후 추가할 다른 외부 지표들)
```



---

## 주요 CSV 파일 설명

| 파일명 | 역할/내용 |
| --- | --- |
| `FINAL_DATA_CLEANED_READY.csv` | 여러 소스에서 크롤링한 원본 데이터를 기본적인 정제(삭제된 글, 너무 짧은 글, 비영어 등)까지 마친 통합본 |
| `FINAL_DATA_FILTERED_#TRUE.csv` | 위 통합본에서 코로나/백신 관련 키워드가 포함된 행만 남긴 버전. True/False 중, 분석에 사용하는 “관련 있음” 데이터 |
| `FINAL_DATA_ROWS_#DELETED.csv` | TRUE 데이터 중에서도 링크만 공유하거나 의견/감정이 거의 없는 문장을 추가로 제거한 버전 |
| `FEAR#.csv` | 외부에서 가져온 공포·탐욕 지수(Fear-Greed Index) 시계열 데이터. 날짜 기준으로 부정 비율 시계열과 합쳐 상관/DTW 분석에 사용 |
| `DDDD.csv` | 최종 분석용 메인 데이터셋. 전처리 + 주제 필터링 + 링크/중립 삭제까지 거친 후, DeBERTa Binary 모델의 감성 라벨이 부여된 상태의 데이터 |
| `labeled_output#.csv`, `10_per#_final.csv` | 전체 데이터 중 약 10%를 샘플링해 사람이 직접 부정/중립/긍정 라벨을 붙인 결과. 모델 학습/검증에 사용되는 골드 레이블 세트 |


## 9. 부록 (Appendix – 시행착오 & 중간 결과 정리)

본문에서는 전체 스토리 흐름과 최종 파이프라인에 집중하고,  
이 부록에서는 **시행착오 과정에서 얻은 중간 결과와 교훈**만 정리한다.

---

### 9.1 KoELECTRA & Three-Class 실험 상세

#### 9.1.1 초기 라벨링 기준 & 분포

정제된 데이터 중 약 **10% (2,200~2,300개)**를 샘플링하여  
다음 두 가지 라벨을 동시에 부여했다.

- **Binary**
  - `0 = 부정`, `1 = 긍정`
- **Three-Class**
  - `0 = 부정`, `1 = 중립`, `2 = 긍정`

라벨 분포는 대략 다음과 같았다.

- **Binary**
  - 부정: **약 81.2%**
  - 긍정: **약 18.8%**

- **Three-Class**
  - 부정: **약 63.5%**
  - 중립: **약 17.6%**
  - 긍정: **약 18.9%**

→ 이미 **라벨링 단계에서 부정이 압도적으로 많고, 중립이 상대적으로 적은 구조**라는 점을 확인했다.

---

#### 9.1.2 KoELECTRA 기반 Three-Class 성능

초기에는 한국어 데이터까지 고려하여 **KoELECTRA**를 이용해  
Binary / Three-Class 실험을 모두 진행했다.

- **Binary 실험**
  - Validation Accuracy: **약 0.81 ~ 0.82**

- **Three-Class 실험**
  - Validation Accuracy: **약 0.63** 수준
  - Macro-F1: 대략 **0.2 ~ 0.3** 수준에 머무름
  - 특히 **중립(1) 클래스의 Recall/F1-score가 거의 0에 가까움**

Confusion Matrix 관찰 결과:

- 실제 중립/긍정 문장을 **부정(0)**으로 예측하는 비율이 높고,
- 모델이 사실상 **“부정 vs 나머지”** 구조로 수렴하는 경향이 있었다.

여러 조합을 시도했지만,

- Epoch 수 조절  
- 학습률(LR) 변경  
- Dropout 조정  
- Class Weight, Oversampling, Focal Loss 결합  

등을 적용해도 **Three-Class에서 중립 클래스만큼은 끝까지 안정적으로 분리되지 않는 문제**가 남았다.

---

#### 9.1.3 라벨링 기준 재정의 & 교훈

이 문제를 해결하기 위해:

1. **라벨링 기준을 더 명확하게 재정의**하고,
2. 애매한 문장(사실 전달 + 미묘한 감정)을 다시 읽으면서  
   - 중립 ↔ 부정  
   - 중립 ↔ 긍정  
   경계에 있는 샘플을 재라벨링했다.
3. **감정 표현이 거의 없는 문장**은 라벨링 대상에서 제외하여  
   **라벨 노이즈를 줄이는 쪽으로 정리**했다.

그럼에도 불구하고, 전체 데이터 구조 자체가:

- **부정이 매우 많은 불균형 데이터**,  
- 중립에 대한 **일관된 기준 잡기가 어려운 문제**

를 가지고 있었기 때문에,

> “이 데이터셋에서는 3-Class보다는  
> **Binary(부정 vs 긍정)**에 집중하는 것이 더 타당하다”

는 결론에 도달했고,  
최종 파이프라인을 **Binary DeBERTa v3 모델 중심**으로 설계하게 되었다.

---

### 9.2 불균형 해결 전략 – 시도와 중간 결과

데이터 자체가 **부정 ≈ 80% 이상**인 구조라,  
불균형을 줄이기 위한 여러 전략을 실험했다.

#### 9.2.1 Oversampling (소수 클래스 복제)

- **방법**
  - 긍정/중립 데이터(소수 클래스)를 **중복 샘플링**하여  
    학습 데이터에서의 클래스 비율을 완화

- **관찰**
  - 초기 Epoch에서는 **F1-score가 소폭 좋아지는 경향**
  - 하지만 Epoch를 늘리면
    - 소수 클래스 샘플 일부에 **과적합(overfitting)** 되는 패턴
    - Validation Loss가 오히려 출렁이면서 **불안정해지는 구간**도 관찰

→ **결론**

- **“완전 균형”을 맞출 정도의 강한 oversampling**은 적합하지 않았고,
- 이후에는 **“부분적인 완화” 수준**으로만 사용하거나  
  다른 기법(Class Weight 등)과 **조합**하여 사용.

---

#### 9.2.2 Class Weight (가중치 기반 손실 조정)

- **방법**
  - `CrossEntropyLoss(weight=class_weights)` 형태로,  
    클래스별 **샘플 수의 역수** 등에 비례한 가중치를 부여

- **예시 (Three-Class 기준, 개념적 형태)**

| 클래스 | 의미 | 개수 | 가중치 예시 |
|--------|------|------|------------|
| 0      | 부정 | 1165 | 0.52       |
| 1      | 중립 | 325  | 1.88       |
| 2      | 긍정 | 345  | 1.77       |

- **관찰**
  - 전혀 가중치를 주지 않았을 때보다  
    **소수 클래스(중립/긍정)에 대한 Recall이 상향 조정**되는 효과
  - 특히 **Binary 실험**에서
    - Validation Accuracy가 **0.80 → 0.84** 수준으로 개선되는 패턴

→ **결론**

- **Class Weight**는 텍스트 불균형 문제에서  
  **“기본 옵션”으로 쓸 만하다**는 것을 확인했고,
- 최종 DeBERTa Binary 모델에도  
  **Class Weight 기반 손실**을 사용하는 방향으로 굳혔다.

---

#### 9.2.3 Focal Loss

- **목적**
  - **쉬운 샘플보다 어려운(오분류된) 샘플**에 더 큰 가중치를 부여해  
    소수 클래스 학습을 돕는 것

- **적용**
  - DeBERTa 계열 실험에서  
    **Focal Loss + Class Weight + (부분적) Oversampling**을 함께 적용

- **관찰**
  - 일부 세팅에서는 **Train Accuracy 95~99%**까지 빠르게 도달
  - Validation Accuracy는 **0.86 ~ 0.87** 수준에서 수렴
  - 다만,
    - Focal Loss의 파라미터(gamma 등)에 **민감**
    - 잘못 설정하면 Loss가 **불안정하게 튀는 경우**도 존재

→ **결론**

- Focal Loss는 불균형이 심한 상황에서  
  **DeBERTa Binary 모델을 조금 더 안정적으로 끌어올리는 데 유효**했지만,
- 지나치게 복잡한 조합보다는  
  **“Class Weight + 적당한 Epoch + Early Stopping”**이  
  실용성·안정성 면에서 더 중요했다.

---

### 9.3 전처리 버전 비교 – “토픽이 깨끗해질 때까지”

전처리는 여러 버전을 거치면서 점진적으로 강화되었다.  
여기서는 **대표적인 세 가지 버전**만 정리한다.

#### 9.3.1 버전 A – 최소 전처리

- **수행한 것**
  - 기본적인 특수문자 제거
  - 소문자 변환

- **관찰**
  - LDA 토픽 상위 키워드에
    - `http`, `www`, `com`, `trump`, `biden`, `news` 등
    - **링크, 정치인 이름, 사이트 이름**이 과도하게 등장
  - “코로나/백신”보다 **정치·링크 구조**가 더 강하게 드러나는 토픽이 많음

→ **결론**

- **“이 정도 전처리로는 ‘백신 논란의 구조’를 보기 어렵다”**는 것을 확인.

---

#### 9.3.2 버전 B – 특수문자/URL/불용어 + 기본 필터링

- **수행한 것**
  - URL, 이모티콘, 각종 특수문자 제거
  - 일반적인 불용어(stopwords) 제거

- **관찰**
  - LDA 토픽에서
    - `mask`, `vaccine`, `company`, `money`, `hospital` 등  
      **의미 있는 단어들**이 등장하기 시작
  - 그러나 여전히
    - 코로나/백신과 **직접 관련 없는 잡담**도 다수 포함

→ **결론**

- **“텍스트 자체는 깨끗해졌지만, 여전히 주제와 무관한 문장이 많다”**  
- → **주제 관련성(Relevance) 필터링 단계** 필요.

---

#### 9.3.3 버전 C – 키워드 기반 주제 관련성 필터링

- **수행한 것**
  - `vaccine`, `covid`, `coronavirus`, `side effect`, `pfizer`, `moderna`,  
    `mandate`, `mask`, `hospital`, `mrna` 등  
    코로나/백신 이슈에서 실제로 자주 등장하는 **키워드 리스트**를 만들고,
  - 문장 내에 이 키워드가 **하나도 없으면 “주제 무관(False)”로 제거**

- **결과**
  - ✅ True (관련 있음): **23,939건**  
  - ❌ False (관련 없음): **75,338건** (분석 제외)

이후 True 데이터 10% 샘플을 직접 검토한 결과:

- 대부분 실제로 **코로나/백신 논의**였음
- 다만 **링크 공유·정보 전달 위주**로,  
  감정·의견이 거의 없는 문장은 추가로 삭제 필요

→ **결론**

- **“텍스트를 깨끗하게 만드는 전처리” +  
  “주제에 맞는 텍스트만 남기는 필터링”**  
  두 축이 모두 중요하다는 것을 확인했고,
- 최종 파이프라인은 **이 버전 C를 기반으로 구축**했다.

---

### 9.4 토픽 모델링 – LDA → BERTopic 전환 과정

#### 9.4.1 LDA (초기 토픽 모델링)

- **설정**
  - BoW 기반 벡터화
  - 토픽 개수: **10개** (여러 값 실험 후 기준값으로 사용)

- **장점**
  - 구현이 간단하고, 토픽 단어 리스트 해석이 직관적

- **한계**
  - 전처리가 조금만 부족해도
    - URL, 정치인 이름, 사이트 이름이 섞인 **가비지 토픽** 발생
  - 문장 길이·표현 다양성이 큰 Reddit/포럼 데이터에서는  
    **“정교한 클러스터링”에 한계**

---

#### 9.4.2 BERTopic + HDBSCAN

- **구성**
  - 문장을 임베딩으로 변환
  - **HDBSCAN**으로 밀도 기반 클러스터링 수행
  - 토픽별 대표 단어/문장을 기반으로 사람이 레이블 부여

- **장점**
  - 밀집도가 낮은 문서를 **노이즈(Topic = -1)**로 자동 분리
  - 문장 단위 의미를 더 잘 반영하여,
    - “의료비/병원 시스템 불만”
    - “마스크/상점 규정 갈등”
    - “음모론·hoax 프레이밍”  
    같은 토픽이 더 **선명하게 분리**됨

→ **결론**

- LDA는 **“대략적인 윤곽”**을 파악하는 데는 도움이 되었지만,  
- 최종적으로는 **BERTopic이  
  감성(부정/긍정)과 함께 토픽 구조를 해석하는 데 더 적합**하다고 판단하여  
  이 방향으로 모델링을 마무리했다.

---

### 9.5 최종 DeBERTa v3 모델 선택 과정

DeBERTa v3 Binary 모델의 **Epoch별 대표 로그**는 다음과 같다.

| Epoch | Train Loss | Train Acc | Val Acc |
|-------|-----------:|----------:|--------:|
| 1     | 0.26       | 0.51      | 0.18    |
| 2     | 0.12       | 0.80      | 0.81    |
| 3     | 0.05       | 0.96      | 0.87    |
| 4     | 0.03       | 0.98      | 0.84    |
| 5     | 0.02       | 0.99      | 0.87    |

- **Epoch 1 → 2**
  - 모델이 **기본적인 패턴을 학습**하면서  
    Validation Accuracy가 **0.18 → 0.81**로 급상승
- **Epoch 3**
  - Train Accuracy ≈ **0.96**, Val Accuracy ≈ **0.87**로  
    **일반화 성능이 가장 잘 나오는 구간** 중 하나
- **Epoch 4**
  - Train Accuracy는 올라가지만  
    Val Accuracy가 **0.84**로 잠시 떨어지는 패턴 (**과적합 시작 시그널**)
- **Epoch 5**
  - Train Accuracy ≈ **0.99**, Val Accuracy ≈ **0.87**로 회복

→ **종합 판단**

- **Epoch 3~5 구간**이 성능·안정성 면에서 적절
- 너무 많은 Epoch는
  - Train Loss는 떨어지지만
  - 실제로는 **라벨 노이즈/특정 표현에 과적합**할 수 있다고 판단

그래서 최종 실험에서는

- **3~5 Epoch 사이**에서 Early Stopping 기준을 잡고,  
- Validation 성능과 **결과 해석의 일관성**을 함께 고려해  
  **현재 DeBERTa v3 Binary 모델**을 최종 선택했다.

---

### 9.6 재현·확장 시 참고 사항

향후 이 프로젝트를 확장하거나 다시 재현할 때,  
시행착오를 줄이기 위해 남겨두는 메모:

1. **3-Class보다는 Binary 추천**
   - 같은 데이터 구조라면  
     **부정/긍정 Binary**가 훨씬 안정적이다.

2. **전처리 → 주제 필터링 순서 유지**
   - 텍스트를 먼저 **깨끗하게 만든 뒤**,  
     **주제 관련성 필터**를 적용하는 순서가 중요하다.

3. **불균형 대응은 “적당히”**
   - Oversampling, Focal Loss는  
     **“과하게 쓰면” 오히려 불안정**해진다.
   - **Class Weight + 적절한 Epoch + Early Stopping** 조합이  
     현실적인 선택이었다.

4. **토픽 모델링은 BERTopic 위주**
   - LDA는 **rough check 용도**로만 사용하고,
   - 최종 해석은 **BERTopic 결과에 기반**하는 것이 좋다.

> 이 부록에 정리된 시행착오는  
> “실패한 코드/로그”가 아니라  
> **어떤 선택을 했고, 무엇을 버리고 무엇을 채택했는지**에 대한  
> 중간 결과와 의사결정 기록으로 남겨 두었다.

### 9.7 Reddit 크롤링 세부 전략 (PRAW 기반 구현)

> 본 절에서는 2.4절에서 개략만 제시한 Reddit 데이터 수집 과정을  
> 실제 코드 수준에서 조금 더 상세히 정리한다.

(여기에 이전에 정리해 둔 아래 내용 붙이기)
- PRAW 인증 & 클라이언트 설정
- 타깃 서브레딧 리스트
- `subreddit.top(time_filter="all", limit=POST_LIMIT)` 사용 방식
- `submission.comments.replace_more(limit=None)` + `submission.comments.list()`로 전체 댓글 트리 수집
- `[deleted]/[removed]` 필터, 길이 필터 코드
- CSV 저장 및 `created_utc` → `created_at` 변환 과정 요약

###  프로젝트가 한 일 (요약)

1. 여러 사이트(포럼·리뷰·Q&A 등)에서  
   **코로나/백신 관련 댓글·리뷰 약 10만 건**을 **키워드 기반**으로 크롤링
2. **다단계 전처리 + 주제 관련성 필터링**을 통해  
   **실제로 코로나/백신 논의에 해당하는 텍스트만 남긴 고순도 데이터셋** 구축
3. 약 **2,200개** 댓글을 사람이 직접 라벨링하여  
   **DeBERTa v3 기반 감성 분류 모델 (Val. Acc ≈ 0.87)** 학습
4. 감성 라벨과 **BERTopic 토픽 모델링**을 결합해  
   “**무슨 이슈가 부정 여론을 끌어올렸는지**”를 분석



